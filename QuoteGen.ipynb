{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "\n",
    "ids = np.load('quote_matrix10.npy')\n",
    "#ids = ids[:1000,:]\n",
    "ids = ids[1000:1999,:]\n",
    "\n",
    "int_to_word = np.load('int_to_word10.npy')\n",
    "word_to_int = np.load('word_to_int10.npy')\n",
    "\n",
    "int_to_word = int_to_word.item()\n",
    "word_to_int = word_to_int.item()\n",
    "\n",
    "int_to_word[0] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[]:\n",
    "text = []\n",
    "for quote in ids:\n",
    "    for word in quote:\n",
    "        if not word==0:\n",
    "            text.append(word)\n",
    "\n",
    "text = np.ndarray.flatten(np.asarray(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 28951\n"
     ]
    }
   ],
   "source": [
    "# In[]: cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 10\n",
    "step = 1\n",
    "seq = []\n",
    "next_seq = []\n",
    "quote_len = text.shape[0]\n",
    "\n",
    "for i in range(0, quote_len - maxlen, step):\n",
    "    seq.append(text[i: i + maxlen])\n",
    "    next_seq.append(text[i + maxlen])\n",
    "\n",
    "print('nb sequences:', len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = np.asarray(seq)\n",
    "next_seq = np.asarray(next_seq)\n",
    "\n",
    "max_word = np.asarray(len(int_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6086,  8180, 11656, ..., 13269,  1809,  1190],\n",
       "        [ 8180, 11656,  3785, ...,  1809,  1190,   137],\n",
       "        [11656,  3785, 12205, ...,  1190,   137,  9885],\n",
       "        ..., \n",
       "        [ 4942, 12217, 12374, ...,  8415, 12213,  4602],\n",
       "        [12217, 12374,  1197, ..., 12213,  4602,  5724],\n",
       "        [12374,  1197,  7918, ...,  4602,  5724,  6485]], dtype=int32),\n",
       " array([ 137, 9885, 4601, ..., 5724, 6485, 2813], dtype=int32),\n",
       " (28951, 10),\n",
       " (28951,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq, next_seq, seq.shape, next_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_advanced(x):\n",
    "    return K.relu(x, max_value=max_word)\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(seq, (len(seq), maxlen, 1))\n",
    "# normalize\n",
    "X = X / max_word\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(next_seq, num_classes= max_word)\n",
    "#y = np.reshape(next_seq,(next_seq.shape[0],1)) / max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, input_shape=(\n",
    "                            None, #X.shape[1], \n",
    "                            X.shape[2]),\n",
    "               #return_sequences=True,\n",
    "               #activation='sigmoid'\n",
    "               ))\n",
    "\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(LSTM(y.shape[1]\n",
    "#                ,activation='sigmoid'\n",
    "#                ))\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(1024))\n",
    "\n",
    "model.add(Dense(y.shape[1]))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#optimizer = RMSprop(lr=0.01)\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28951, 10, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[8]:\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    # preds = preds[1:]\n",
    "    # preds = np.asarray(preds).astype('float64')\n",
    "    # preds = np.log(preds) / temperature\n",
    "    # exp_preds = np.exp(preds)\n",
    "    # preds = exp_preds / np.sum(exp_preds)\n",
    "    # probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(preds)\n",
    "    #return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        print(sentence)\n",
    "        generated.join([str([int_to_word[value]]).join(' ') for value in sentence])\n",
    "        print('----- Generating with seed: %s'%[int_to_word[word] for word in sentence])\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(15):\n",
    "            x_pred = np.reshape(sentence,(1, \n",
    "                                          -1, #maxlen, \n",
    "                                          1))\n",
    "            x_pred = x_pred / max_word\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            preds = preds[0]\n",
    "            # print(preds.shape)\n",
    "            next_index = round(sample(preds, diversity))\n",
    "            print(next_index)\n",
    "            next_char = int_to_word[next_index]\n",
    "\n",
    "            generated.join(str(next_char))\n",
    "            sentence = np.append(\n",
    "                                sentence, #sentence[1:],\n",
    "                                 next_index)\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.write(\" \")\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "filepath=\"trained_weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27503 samples, validate on 1448 samples\n",
      "Epoch 1/1\n",
      "27503/27503 [==============================] - 96s 3ms/step - loss: 6.9087 - val_loss: 6.7534\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "[ 8040  6142  1212 13055  6172 12374  7577  4934  6035  8132]\n",
      "----- Generating with seed: ['my', 'immunity', 'became', 'very', 'important', 'to', 'me', 'for', 'i', 'needed']\n",
      "4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family \n",
      "----- diversity: 0.5\n",
      "[ 8040  6142  1212 13055  6172 12374  7577  4934  6035  8132]\n",
      "----- Generating with seed: ['my', 'immunity', 'became', 'very', 'important', 'to', 'me', 'for', 'i', 'needed']\n",
      "4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family \n",
      "----- diversity: 1.0\n",
      "[ 8040  6142  1212 13055  6172 12374  7577  4934  6035  8132]\n",
      "----- Generating with seed: ['my', 'immunity', 'became', 'very', 'important', 'to', 'me', 'for', 'i', 'needed']\n",
      "4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family \n",
      "----- diversity: 1.2\n",
      "[ 8040  6142  1212 13055  6172 12374  7577  4934  6035  8132]\n",
      "----- Generating with seed: ['my', 'immunity', 'became', 'very', 'important', 'to', 'me', 'for', 'i', 'needed']\n",
      "4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family 4601\n",
      "family \n",
      "\n",
      "Epoch 00001: loss improved from inf to 6.90873, saving model to trained_weights/weights-improvement-01-6.9087-bigger.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe388248048>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          validation_split=0.05,\n",
    "          callbacks=[print_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
