{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "\n",
    "ids = np.load('quote_matrix10.npy')\n",
    "#ids = ids[:1000,:]\n",
    "ids = ids[1000:1999,:]\n",
    "\n",
    "int_to_word = np.load('int_to_word10.npy')\n",
    "word_to_int = np.load('word_to_int10.npy')\n",
    "\n",
    "int_to_word = int_to_word.item()\n",
    "word_to_int = word_to_int.item()\n",
    "\n",
    "int_to_word[0] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[]:\n",
    "text = []\n",
    "for quote in ids:\n",
    "    for word in quote:\n",
    "        if not word==0:\n",
    "            text.append(word)\n",
    "\n",
    "text = np.ndarray.flatten(np.asarray(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 28951\n"
     ]
    }
   ],
   "source": [
    "# In[]: cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 10\n",
    "step = 1\n",
    "seq = []\n",
    "next_seq = []\n",
    "quote_len = text.shape[0]\n",
    "\n",
    "for i in range(0, quote_len - maxlen, step):\n",
    "    seq.append(text[i: i + maxlen])\n",
    "    next_seq.append(text[i + maxlen])\n",
    "\n",
    "print('nb sequences:', len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = np.asarray(seq)\n",
    "next_seq = np.asarray(next_seq)\n",
    "\n",
    "max_word = np.asarray(len(int_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 6086,  8180, 11656, ..., 13269,  1809,  1190],\n",
       "        [ 8180, 11656,  3785, ...,  1809,  1190,   137],\n",
       "        [11656,  3785, 12205, ...,  1190,   137,  9885],\n",
       "        ..., \n",
       "        [ 4942, 12217, 12374, ...,  8415, 12213,  4602],\n",
       "        [12217, 12374,  1197, ..., 12213,  4602,  5724],\n",
       "        [12374,  1197,  7918, ...,  4602,  5724,  6485]], dtype=int32),\n",
       " array([ 137, 9885, 4601, ..., 5724, 6485, 2813], dtype=int32),\n",
       " (28951, 10),\n",
       " (28951,),\n",
       " array(13661))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq, next_seq, seq.shape, next_seq.shape, max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'your'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_word[13636]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_advanced(x):\n",
    "    return K.relu(x, max_value=max_word)\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(seq, (len(seq), maxlen, 1))\n",
    "# normalize\n",
    "X = X / max_word\n",
    "# one hot encode the output variable\n",
    "#y = to_categorical(next_seq, num_classes= max_word)\n",
    "y = np.reshape(next_seq,(next_seq.shape[0],1)) #/ max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28951, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, input_shape=(\n",
    "                            X.shape[1], #None , \n",
    "                            X.shape[2]),\n",
    "               #return_sequences=True,\n",
    "               #activation='sigmoid'\n",
    "               #unroll=True\n",
    "               ))\n",
    "\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "#model.add(LSTM(256))\n",
    "# model.add(LSTM(y.shape[1]\n",
    "#                ,activation='sigmoid'\n",
    "#                ))\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32))\n",
    "\n",
    "model.add(Dense(y.shape[1]\n",
    "                ,activation=relu_advanced #'sigmoid'#relu_advanced # 0 to max_word\n",
    "               ))\n",
    "\n",
    "#model.add(Activation('softmax'))\n",
    "\n",
    "#optimizer = RMSprop(lr=0.01)\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "#    loss= 'mean_squared_logarithmic_error',  #'sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28951, 10, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[8]:\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    # preds = preds[1:]\n",
    "    # preds = np.asarray(preds).astype('float64')\n",
    "    # preds = np.log(preds) / temperature\n",
    "    # exp_preds = np.exp(preds)\n",
    "    # preds = exp_preds / np.sum(exp_preds)\n",
    "    # probas = np.random.multinomial(1, preds, 1)\n",
    "    #return np.argmax(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        print(sentence)\n",
    "        generated.join([str([int_to_word[value]]).join(' ') for value in sentence])\n",
    "        print('----- Generating with seed: %s'%[int_to_word[word] for word in sentence])\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(15):\n",
    "            x_pred = np.reshape(sentence,(1, \n",
    "                                          -1, #maxlen, \n",
    "                                          1))\n",
    "            x_pred = x_pred / max_word\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            preds = preds[0]\n",
    "            #print(preds.shape)\n",
    "            next_index = round(sample(preds, diversity)[0]) # \n",
    "            #print(next_index)\n",
    "            next_char = int_to_word[next_index]\n",
    "\n",
    "            generated.join(str(next_char))\n",
    "            sentence = np.append(\n",
    "                               sentence[1:], # sentence[1:],  \n",
    "                                 next_index)\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.write(\" \")\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "filepath=\"trained_weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27503 samples, validate on 1448 samples\n",
      "Epoch 1/1000\n",
      "27503/27503 [==============================] - 15s 551us/step - loss: 18028483.4006 - val_loss: 18229724.0663\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "[ 7311  4934  8478  2086 13473   137  4601  7430   525  6207]\n",
      "----- Generating with seed: ['love', 'for', 'ones', 'children', 'without', 'a', 'family', 'man', 'alone', 'in']\n",
      "literally literally literally literally literally literally literally literally literally literally literally literally literally literally literally \n",
      "----- diversity: 0.5\n",
      "[ 7311  4934  8478  2086 13473   137  4601  7430   525  6207]\n",
      "----- Generating with seed: ['love', 'for', 'ones', 'children', 'without', 'a', 'family', 'man', 'alone', 'in']\n",
      "literally literally literally literally literally literally literally literally literally literally literally literally literally literally literally \n",
      "----- diversity: 1.0\n",
      "[ 7311  4934  8478  2086 13473   137  4601  7430   525  6207]\n",
      "----- Generating with seed: ['love', 'for', 'ones', 'children', 'without', 'a', 'family', 'man', 'alone', 'in']\n",
      "literally literally literally literally literally literally literally literally literally literally literally literally literally literally literally \n",
      "----- diversity: 1.2\n",
      "[ 7311  4934  8478  2086 13473   137  4601  7430   525  6207]\n",
      "----- Generating with seed: ['love', 'for', 'ones', 'children', 'without', 'a', 'family', 'man', 'alone', 'in']\n",
      "literally literally literally literally literally literally literally literally literally literally literally literally literally literally literally \n",
      "\n",
      "Epoch 00001: loss improved from 18407170.80446 to 18028483.40065, saving model to trained_weights/weights-improvement-01-18028483.4006-bigger.hdf5\n",
      "Epoch 2/1000\n",
      "27503/27503 [==============================] - 16s 589us/step - loss: 18028647.2218 - val_loss: 18231214.2541\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "[12349  4365 13352  6035   546  9795  6035  7169 12374  1190]\n",
      "----- Generating with seed: ['time', 'except', 'when', 'i', 'am', 'racing', 'i', 'like', 'to', 'be']\n",
      "listen listen listen listen listen listen listen listen listen listen listen listen listen listen listen \n",
      "----- diversity: 0.5\n",
      "[12349  4365 13352  6035   546  9795  6035  7169 12374  1190]\n",
      "----- Generating with seed: ['time', 'except', 'when', 'i', 'am', 'racing', 'i', 'like', 'to', 'be']\n",
      "listen listen listen listen listen listen listen listen listen listen listen listen listen listen listen \n",
      "----- diversity: 1.0\n",
      "[12349  4365 13352  6035   546  9795  6035  7169 12374  1190]\n",
      "----- Generating with seed: ['time', 'except', 'when', 'i', 'am', 'racing', 'i', 'like', 'to', 'be']\n",
      "listen listen listen listen listen listen listen listen listen listen listen listen listen listen listen \n",
      "----- diversity: 1.2\n",
      "[12349  4365 13352  6035   546  9795  6035  7169 12374  1190]\n",
      "----- Generating with seed: ['time', 'except', 'when', 'i', 'am', 'racing', 'i', 'like', 'to', 'be']\n",
      "listen listen listen listen listen listen listen listen listen listen listen listen listen listen listen \n",
      "\n",
      "Epoch 00002: loss did not improve from 18028483.40065\n",
      "Epoch 3/1000\n",
      "27503/27503 [==============================] - 17s 607us/step - loss: 18029058.6268 - val_loss: 18227958.4420\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "[5724 8330  611 3930  611 7094 8466  479  611 2140]\n",
      "----- Generating with seed: ['health', 'nutrition', 'and', 'education', 'and', 'less', 'on', 'alcohol', 'and', 'cigarettes']\n",
      "liver liver liver liver liver liver liver liver liver liver liver liver liver liver liver \n",
      "----- diversity: 0.5\n",
      "[5724 8330  611 3930  611 7094 8466  479  611 2140]\n",
      "----- Generating with seed: ['health', 'nutrition', 'and', 'education', 'and', 'less', 'on', 'alcohol', 'and', 'cigarettes']\n",
      "liver liver liver liver liver liver liver liver liver liver liver liver liver liver liver \n",
      "----- diversity: 1.0\n",
      "[5724 8330  611 3930  611 7094 8466  479  611 2140]\n",
      "----- Generating with seed: ['health', 'nutrition', 'and', 'education', 'and', 'less', 'on', 'alcohol', 'and', 'cigarettes']\n",
      "liver liver liver liver liver liver liver liver liver liver liver liver liver liver liver \n",
      "----- diversity: 1.2\n",
      "[5724 8330  611 3930  611 7094 8466  479  611 2140]\n",
      "----- Generating with seed: ['health', 'nutrition', 'and', 'education', 'and', 'less', 'on', 'alcohol', 'and', 'cigarettes']\n",
      "liver liver liver liver liver liver liver liver liver liver liver liver liver liver liver \n",
      "\n",
      "Epoch 00003: loss did not improve from 18028483.40065\n",
      "Epoch 4/1000\n",
      "27503/27503 [==============================] - 15s 539us/step - loss: 18028122.7604 - val_loss: 18225421.1381\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "[11283  6674 13236  5966  6035 13210 12374 11562  6674  4707]\n",
      "----- Generating with seed: ['so', 'it', 'was', 'how', 'i', 'wanted', 'to', 'start', 'it', 'felt']\n",
      "locks locks locks locks locks locks locks locks locks locks locks locks locks locks locks \n",
      "----- diversity: 0.5\n",
      "[11283  6674 13236  5966  6035 13210 12374 11562  6674  4707]\n",
      "----- Generating with seed: ['so', 'it', 'was', 'how', 'i', 'wanted', 'to', 'start', 'it', 'felt']\n",
      "locks locks locks locks locks locks locks locks locks locks locks locks locks locks locks \n",
      "----- diversity: 1.0\n",
      "[11283  6674 13236  5966  6035 13210 12374 11562  6674  4707]\n",
      "----- Generating with seed: ['so', 'it', 'was', 'how', 'i', 'wanted', 'to', 'start', 'it', 'felt']\n",
      "locks locks locks locks locks locks locks locks locks locks locks locks locks locks locks \n",
      "----- diversity: 1.2\n",
      "[11283  6674 13236  5966  6035 13210 12374 11562  6674  4707]\n",
      "----- Generating with seed: ['so', 'it', 'was', 'how', 'i', 'wanted', 'to', 'start', 'it', 'felt']\n",
      "locks locks locks locks locks locks locks locks locks locks locks locks locks locks locks \n",
      "\n",
      "Epoch 00004: loss improved from 18028483.40065 to 18028122.76035, saving model to trained_weights/weights-improvement-04-18028122.7604-bigger.hdf5\n",
      "Epoch 5/1000\n",
      "27503/27503 [==============================] - 15s 543us/step - loss: 18029144.5938 - val_loss: 18225265.3481\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "[ 1954  6918  8040  2864  8040  1664  8040 11162 12247  3725]\n",
      "----- Generating with seed: ['central', 'la', 'my', 'cousins', 'my', 'brothers', 'my', 'sisters', 'they', 'dont']\n",
      "lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty \n",
      "----- diversity: 0.5\n",
      "[ 1954  6918  8040  2864  8040  1664  8040 11162 12247  3725]\n",
      "----- Generating with seed: ['central', 'la', 'my', 'cousins', 'my', 'brothers', 'my', 'sisters', 'they', 'dont']\n",
      "lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty \n",
      "----- diversity: 1.0\n",
      "[ 1954  6918  8040  2864  8040  1664  8040 11162 12247  3725]\n",
      "----- Generating with seed: ['central', 'la', 'my', 'cousins', 'my', 'brothers', 'my', 'sisters', 'they', 'dont']\n",
      "lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty \n",
      "----- diversity: 1.2\n",
      "[ 1954  6918  8040  2864  8040  1664  8040 11162 12247  3725]\n",
      "----- Generating with seed: ['central', 'la', 'my', 'cousins', 'my', 'brothers', 'my', 'sisters', 'they', 'dont']\n",
      "lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty lofty \n",
      "\n",
      "Epoch 00005: loss did not improve from 18028122.76035\n",
      "Epoch 6/1000\n",
      "27503/27503 [==============================] - 15s 547us/step - loss: 18028977.1652 - val_loss: 18227005.0608\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "[11891 13626  5305   137  7223  7311 12374   137  2081   611]\n",
      "----- Generating with seed: ['supports', 'you', 'give', 'a', 'little', 'love', 'to', 'a', 'child', 'and']\n",
      "ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 \n",
      "----- diversity: 0.5\n",
      "[11891 13626  5305   137  7223  7311 12374   137  2081   611]\n",
      "----- Generating with seed: ['supports', 'you', 'give', 'a', 'little', 'love', 'to', 'a', 'child', 'and']\n",
      "ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 \n",
      "----- diversity: 1.0\n",
      "[11891 13626  5305   137  7223  7311 12374   137  2081   611]\n",
      "----- Generating with seed: ['supports', 'you', 'give', 'a', 'little', 'love', 'to', 'a', 'child', 'and']\n",
      "ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 \n",
      "----- diversity: 1.2\n",
      "[11891 13626  5305   137  7223  7311 12374   137  2081   611]\n",
      "----- Generating with seed: ['supports', 'you', 'give', 'a', 'little', 'love', 'to', 'a', 'child', 'and']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 ln2 \n",
      "\n",
      "Epoch 00006: loss did not improve from 18028122.76035\n",
      "Epoch 7/1000\n",
      "27503/27503 [==============================] - 15s 533us/step - loss: 18029526.4834 - val_loss: 18224973.1713\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "[12806  8415 10937  2177  1759  6532   611 13152  2576  2635]\n",
      "----- Generating with seed: ['union', 'of', 'several', 'clans', 'by', 'intermarriage', 'and', 'voluntary', 'connection', 'constitutes']\n",
      "logos logos logos logos logos logos logos logos logos logos logos logos logos logos logos \n",
      "----- diversity: 0.5\n",
      "[12806  8415 10937  2177  1759  6532   611 13152  2576  2635]\n",
      "----- Generating with seed: ['union', 'of', 'several', 'clans', 'by', 'intermarriage', 'and', 'voluntary', 'connection', 'constitutes']\n",
      "logos logos logos logos logos logos logos logos logos logos logos logos logos logos logos \n",
      "----- diversity: 1.0\n",
      "[12806  8415 10937  2177  1759  6532   611 13152  2576  2635]\n",
      "----- Generating with seed: ['union', 'of', 'several', 'clans', 'by', 'intermarriage', 'and', 'voluntary', 'connection', 'constitutes']\n",
      "logos logos logos logos logos logos logos logos logos logos logos logos logos logos logos \n",
      "----- diversity: 1.2\n",
      "[12806  8415 10937  2177  1759  6532   611 13152  2576  2635]\n",
      "----- Generating with seed: ['union', 'of', 'several', 'clans', 'by', 'intermarriage', 'and', 'voluntary', 'connection', 'constitutes']\n",
      "logos logos logos logos logos logos logos logos logos logos logos logos logos logos logos \n",
      "\n",
      "Epoch 00007: loss did not improve from 18028122.76035\n",
      "Epoch 8/1000\n",
      "27503/27503 [==============================] - 15s 536us/step - loss: 18024941.7599 - val_loss: 18247817.5912\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "[11901   923   137  7770 12205 12247  5698 12208 13055  1161]\n",
      "----- Generating with seed: ['sure', 'at', 'a', 'minimum', 'that', 'they', 'have', 'the', 'very', 'basic']\n",
      "life life life life life life life life life life life life life life life \n",
      "----- diversity: 0.5\n",
      "[11901   923   137  7770 12205 12247  5698 12208 13055  1161]\n",
      "----- Generating with seed: ['sure', 'at', 'a', 'minimum', 'that', 'they', 'have', 'the', 'very', 'basic']\n",
      "life life life life life life life life life life life life life life life \n",
      "----- diversity: 1.0\n",
      "[11901   923   137  7770 12205 12247  5698 12208 13055  1161]\n",
      "----- Generating with seed: ['sure', 'at', 'a', 'minimum', 'that', 'they', 'have', 'the', 'very', 'basic']\n",
      "life life life life life life life life life life life life life life life \n",
      "----- diversity: 1.2\n",
      "[11901   923   137  7770 12205 12247  5698 12208 13055  1161]\n",
      "----- Generating with seed: ['sure', 'at', 'a', 'minimum', 'that', 'they', 'have', 'the', 'very', 'basic']\n",
      "life life life life life life life life life life life life life life life \n",
      "\n",
      "Epoch 00008: loss improved from 18028122.76035 to 18024941.75988, saving model to trained_weights/weights-improvement-08-18024941.7599-bigger.hdf5\n",
      "Epoch 9/1000\n",
      "27503/27503 [==============================] - 15s 543us/step - loss: 18030661.0670 - val_loss: 18223477.2928\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "[ 1938 12205 13269   497 12027  8588  7278 13269 11637 10977]\n",
      "----- Generating with seed: ['cell', 'that', 'we', 'all', 'take', 'our', 'looks', 'we', 'still', 'share']\n",
      "loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole \n",
      "----- diversity: 0.5\n",
      "[ 1938 12205 13269   497 12027  8588  7278 13269 11637 10977]\n",
      "----- Generating with seed: ['cell', 'that', 'we', 'all', 'take', 'our', 'looks', 'we', 'still', 'share']\n",
      "loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole \n",
      "----- diversity: 1.0\n",
      "[ 1938 12205 13269   497 12027  8588  7278 13269 11637 10977]\n",
      "----- Generating with seed: ['cell', 'that', 'we', 'all', 'take', 'our', 'looks', 'we', 'still', 'share']\n",
      "loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole \n",
      "----- diversity: 1.2\n",
      "[ 1938 12205 13269   497 12027  8588  7278 13269 11637 10977]\n",
      "----- Generating with seed: ['cell', 'that', 'we', 'all', 'take', 'our', 'looks', 'we', 'still', 'share']\n",
      "loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole loophole \n",
      "\n",
      "Epoch 00009: loss did not improve from 18024941.75988\n",
      "Epoch 10/1000\n",
      "27503/27503 [==============================] - 15s 544us/step - loss: 18028844.6350 - val_loss: 18223249.5249\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.2\n",
      "[ 4760  8592  5966 12374  7413  7887 12208 10268  8415 12208]\n",
      "----- Generating with seed: ['figure', 'out', 'how', 'to', 'make', 'money', 'the', 'rest', 'of', 'the']\n",
      "lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie \n",
      "----- diversity: 0.5\n",
      "[ 4760  8592  5966 12374  7413  7887 12208 10268  8415 12208]\n",
      "----- Generating with seed: ['figure', 'out', 'how', 'to', 'make', 'money', 'the', 'rest', 'of', 'the']\n",
      "lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie \n",
      "----- diversity: 1.0\n",
      "[ 4760  8592  5966 12374  7413  7887 12208 10268  8415 12208]\n",
      "----- Generating with seed: ['figure', 'out', 'how', 'to', 'make', 'money', 'the', 'rest', 'of', 'the']\n",
      "lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie \n",
      "----- diversity: 1.2\n",
      "[ 4760  8592  5966 12374  7413  7887 12208 10268  8415 12208]\n",
      "----- Generating with seed: ['figure', 'out', 'how', 'to', 'make', 'money', 'the', 'rest', 'of', 'the']\n",
      "lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie lorrie \n",
      "\n",
      "Epoch 00010: loss did not improve from 18024941.75988\n",
      "Epoch 11/1000\n",
      "27503/27503 [==============================] - 15s 547us/step - loss: 18029248.7601 - val_loss: 18223869.1602\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.2\n",
      "[  611  5276 12296  8535  5011 13463 12208  4601  6688 11657]\n",
      "----- Generating with seed: ['and', 'get', 'three', 'or', 'four', 'with', 'the', 'family', 'ive', 'stopped']\n",
      "longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding \n",
      "----- diversity: 0.5\n",
      "[  611  5276 12296  8535  5011 13463 12208  4601  6688 11657]\n",
      "----- Generating with seed: ['and', 'get', 'three', 'or', 'four', 'with', 'the', 'family', 'ive', 'stopped']\n",
      "longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding \n",
      "----- diversity: 1.0\n",
      "[  611  5276 12296  8535  5011 13463 12208  4601  6688 11657]\n",
      "----- Generating with seed: ['and', 'get', 'three', 'or', 'four', 'with', 'the', 'family', 'ive', 'stopped']\n",
      "longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding \n",
      "----- diversity: 1.2\n",
      "[  611  5276 12296  8535  5011 13463 12208  4601  6688 11657]\n",
      "----- Generating with seed: ['and', 'get', 'three', 'or', 'four', 'with', 'the', 'family', 'ive', 'stopped']\n",
      "longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding longstanding \n",
      "\n",
      "Epoch 00011: loss did not improve from 18024941.75988\n",
      "Epoch 12/1000\n",
      "27503/27503 [==============================] - 15s 547us/step - loss: 18031006.8012 - val_loss: 18224727.2597\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- diversity: 0.2\n",
      "[ 1950  8415 12208  4601   611  4326 12567 12374  9152  5834]\n",
      "----- Generating with seed: ['center', 'of', 'the', 'family', 'and', 'everyone', 'tried', 'to', 'please', 'him']\n",
      "lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier \n",
      "----- diversity: 0.5\n",
      "[ 1950  8415 12208  4601   611  4326 12567 12374  9152  5834]\n",
      "----- Generating with seed: ['center', 'of', 'the', 'family', 'and', 'everyone', 'tried', 'to', 'please', 'him']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier \n",
      "----- diversity: 1.0\n",
      "[ 1950  8415 12208  4601   611  4326 12567 12374  9152  5834]\n",
      "----- Generating with seed: ['center', 'of', 'the', 'family', 'and', 'everyone', 'tried', 'to', 'please', 'him']\n",
      "lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier \n",
      "----- diversity: 1.2\n",
      "[ 1950  8415 12208  4601   611  4326 12567 12374  9152  5834]\n",
      "----- Generating with seed: ['center', 'of', 'the', 'family', 'and', 'everyone', 'tried', 'to', 'please', 'him']\n",
      "lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier lonelier \n",
      "\n",
      "Epoch 00012: loss did not improve from 18024941.75988\n",
      "Epoch 13/1000\n",
      "27503/27503 [==============================] - 15s 535us/step - loss: 18030113.4647 - val_loss: 18223374.6961\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- diversity: 0.2\n",
      "[  167  5857 12208  4601  5674  9137 12208  9464 10444  6207]\n",
      "----- Generating with seed: ['about', 'historically', 'the', 'family', 'has', 'played', 'the', 'primary', 'role', 'in']\n",
      "love love love love love love love love love love love love love love love \n",
      "----- diversity: 0.5\n",
      "[  167  5857 12208  4601  5674  9137 12208  9464 10444  6207]\n",
      "----- Generating with seed: ['about', 'historically', 'the', 'family', 'has', 'played', 'the', 'primary', 'role', 'in']\n",
      "love love love love love love love love love love love love love love love \n",
      "----- diversity: 1.0\n",
      "[  167  5857 12208  4601  5674  9137 12208  9464 10444  6207]\n",
      "----- Generating with seed: ['about', 'historically', 'the', 'family', 'has', 'played', 'the', 'primary', 'role', 'in']\n",
      "love love love love love love love love love love love love love love love \n",
      "----- diversity: 1.2\n",
      "[  167  5857 12208  4601  5674  9137 12208  9464 10444  6207]\n",
      "----- Generating with seed: ['about', 'historically', 'the', 'family', 'has', 'played', 'the', 'primary', 'role', 'in']\n",
      "love love love love love love love love love love love love love love love \n",
      "\n",
      "Epoch 00013: loss did not improve from 18024941.75988\n",
      "Epoch 14/1000\n",
      "27503/27503 [==============================] - 15s 544us/step - loss: 18030375.7212 - val_loss: 18228491.9006\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- diversity: 0.2\n",
      "[6207 4322 4601 6656  544 3785 4934  589 6109 8450]\n",
      "----- Generating with seed: ['in', 'every', 'family', 'is', 'always', 'dreaming', 'for', 'an', 'imaginary', 'older']\n",
      "lived lived lived lived lived lived lived lived lived lived lived lived lived lived lived \n",
      "----- diversity: 0.5\n",
      "[6207 4322 4601 6656  544 3785 4934  589 6109 8450]\n",
      "----- Generating with seed: ['in', 'every', 'family', 'is', 'always', 'dreaming', 'for', 'an', 'imaginary', 'older']\n",
      "lived lived lived lived lived lived lived lived lived lived lived lived lived lived lived \n",
      "----- diversity: 1.0\n",
      "[6207 4322 4601 6656  544 3785 4934  589 6109 8450]\n",
      "----- Generating with seed: ['in', 'every', 'family', 'is', 'always', 'dreaming', 'for', 'an', 'imaginary', 'older']\n",
      "lived lived lived lived lived lived lived lived lived lived lived lived lived lived lived \n",
      "----- diversity: 1.2\n",
      "[6207 4322 4601 6656  544 3785 4934  589 6109 8450]\n",
      "----- Generating with seed: ['in', 'every', 'family', 'is', 'always', 'dreaming', 'for', 'an', 'imaginary', 'older']\n",
      "lived lived lived lived lived lived lived lived lived lived lived lived lived lived lived \n",
      "\n",
      "Epoch 00014: loss did not improve from 18024941.75988\n",
      "Epoch 15/1000\n",
      "27503/27503 [==============================] - 15s 540us/step - loss: 18029675.4361 - val_loss: 18234631.1492\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- diversity: 0.2\n",
      "[  415   497  6656 10566 12205  1809  1190 10566 12922 12208]\n",
      "----- Generating with seed: ['after', 'all', 'is', 'said', 'that', 'can', 'be', 'said', 'upon', 'the']\n",
      "line line line line line line line line line line line line line line line \n",
      "----- diversity: 0.5\n",
      "[  415   497  6656 10566 12205  1809  1190 10566 12922 12208]\n",
      "----- Generating with seed: ['after', 'all', 'is', 'said', 'that', 'can', 'be', 'said', 'upon', 'the']\n",
      "line line line line line line line line line line line line line line line \n",
      "----- diversity: 1.0\n",
      "[  415   497  6656 10566 12205  1809  1190 10566 12922 12208]\n",
      "----- Generating with seed: ['after', 'all', 'is', 'said', 'that', 'can', 'be', 'said', 'upon', 'the']\n",
      "line line line line line line line line line line line line line line line \n",
      "----- diversity: 1.2\n",
      "[  415   497  6656 10566 12205  1809  1190 10566 12922 12208]\n",
      "----- Generating with seed: ['after', 'all', 'is', 'said', 'that', 'can', 'be', 'said', 'upon', 'the']\n",
      "line line line line line line line line line line line line line line line \n",
      "\n",
      "Epoch 00015: loss did not improve from 18024941.75988\n",
      "Epoch 16/1000\n",
      "27503/27503 [==============================] - 16s 594us/step - loss: 18029754.8500 - val_loss: 18232637.3370\n",
      "\n",
      "----- Generating text after Epoch: 15\n",
      "----- diversity: 0.2\n",
      "[13463 12217 13339  6035 13209 12374  3681  6656 12129 11663]\n",
      "----- Generating with seed: ['with', 'them', 'what', 'i', 'want', 'to', 'do', 'is', 'tell', 'stories']\n",
      "lion lion lion lion lion lion lion lion lion lion lion lion lion lion lion \n",
      "----- diversity: 0.5\n",
      "[13463 12217 13339  6035 13209 12374  3681  6656 12129 11663]\n",
      "----- Generating with seed: ['with', 'them', 'what', 'i', 'want', 'to', 'do', 'is', 'tell', 'stories']\n",
      "lion lion lion lion lion lion lion lion lion lion lion lion lion lion lion \n",
      "----- diversity: 1.0\n",
      "[13463 12217 13339  6035 13209 12374  3681  6656 12129 11663]\n",
      "----- Generating with seed: ['with', 'them', 'what', 'i', 'want', 'to', 'do', 'is', 'tell', 'stories']\n",
      "lion lion lion lion lion lion lion lion lion lion lion lion lion lion lion \n",
      "----- diversity: 1.2\n",
      "[13463 12217 13339  6035 13209 12374  3681  6656 12129 11663]\n",
      "----- Generating with seed: ['with', 'them', 'what', 'i', 'want', 'to', 'do', 'is', 'tell', 'stories']\n",
      "lion lion lion lion lion lion lion lion lion lion lion lion lion lion lion \n",
      "\n",
      "Epoch 00016: loss did not improve from 18024941.75988\n",
      "Epoch 17/1000\n",
      "13312/27503 [=============>................] - ETA: 8s - loss: 17960887.8077"
     ]
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "          batch_size=128,\n",
    "          epochs=1000,\n",
    "          validation_split=0.05,\n",
    "          callbacks=[print_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
