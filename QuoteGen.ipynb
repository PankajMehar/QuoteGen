{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "\n",
    "ids = np.load('quote_matrix10.npy')\n",
    "#ids = ids[:1000,:]\n",
    "ids = ids[1000:1999,:]\n",
    "\n",
    "int_to_word = np.load('int_to_word10.npy')\n",
    "word_to_int = np.load('word_to_int10.npy')\n",
    "\n",
    "int_to_word = int_to_word.item()\n",
    "word_to_int = word_to_int.item()\n",
    "\n",
    "int_to_word[0] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[]:\n",
    "text = []\n",
    "for quote in ids:\n",
    "    for word in quote:\n",
    "        if not word==0:\n",
    "            text.append(word)\n",
    "\n",
    "text = np.ndarray.flatten(np.asarray(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[]: cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 10\n",
    "step = 1\n",
    "seq = []\n",
    "next_seq = []\n",
    "quote_len = text.shape[0]\n",
    "\n",
    "for i in range(0, quote_len - maxlen, step):\n",
    "    seq.append(text[i: i + maxlen])\n",
    "    next_seq.append(text[i + maxlen])\n",
    "\n",
    "print('nb sequences:', len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = np.asarray(seq)\n",
    "next_seq = np.asarray(next_seq)\n",
    "\n",
    "max_word = np.asarray(len(int_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, next_seq, seq.shape, next_seq.shape, max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_word[13636]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_advanced(x):\n",
    "    return K.relu(x, max_value=max_word)\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(seq, (len(seq), maxlen, 1))\n",
    "# normalize\n",
    "X = X / max_word\n",
    "# one hot encode the output variable\n",
    "#y = to_categorical(next_seq, num_classes= max_word)\n",
    "y = np.reshape(next_seq,(next_seq.shape[0],1)) #/ max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, input_shape=(\n",
    "                            X.shape[1], #None , \n",
    "                            X.shape[2]),\n",
    "               #return_sequences=True,\n",
    "               #activation='sigmoid'\n",
    "               #unroll=True\n",
    "               ))\n",
    "\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "#model.add(LSTM(256))\n",
    "# model.add(LSTM(y.shape[1]\n",
    "#                ,activation='sigmoid'\n",
    "#                ))\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32))\n",
    "\n",
    "model.add(Dense(y.shape[1]\n",
    "                ,activation=relu_advanced #'sigmoid'#relu_advanced # 0 to max_word\n",
    "               ))\n",
    "\n",
    "#model.add(Activation('softmax'))\n",
    "\n",
    "#optimizer = RMSprop(lr=0.01)\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "#    loss= 'mean_squared_logarithmic_error',  #'sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[8]:\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    # preds = preds[1:]\n",
    "    # preds = np.asarray(preds).astype('float64')\n",
    "    # preds = np.log(preds) / temperature\n",
    "    # exp_preds = np.exp(preds)\n",
    "    # preds = exp_preds / np.sum(exp_preds)\n",
    "    # probas = np.random.multinomial(1, preds, 1)\n",
    "    #return np.argmax(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        print(sentence)\n",
    "        generated.join([str([int_to_word[value]]).join(' ') for value in sentence])\n",
    "        print('----- Generating with seed: %s'%[int_to_word[word] for word in sentence])\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(15):\n",
    "            x_pred = np.reshape(sentence,(1, \n",
    "                                          -1, #maxlen, \n",
    "                                          1))\n",
    "            x_pred = x_pred / max_word\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            preds = preds[0]\n",
    "            #print(preds.shape)\n",
    "            next_index = round(sample(preds, diversity)[0]) # \n",
    "            #print(next_index)\n",
    "            next_char = int_to_word[next_index]\n",
    "\n",
    "            generated.join(str(next_char))\n",
    "            sentence = np.append(\n",
    "                               sentence[1:], # sentence[1:],  \n",
    "                                 next_index)\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.write(\" \")\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "filepath=\"trained_weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y,\n",
    "          batch_size=128,\n",
    "          epochs=1000,\n",
    "          validation_split=0.05,\n",
    "          callbacks=[print_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
